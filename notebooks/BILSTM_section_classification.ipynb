{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMwOQfHPw1ccKNuQyxrZGM8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asxd-10/cis5300_project/blob/main/notebooks/BILSTM_section_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYnmLbEiOzvP",
        "outputId": "8a56759b-c7d7-4e3a-f8e0-62d9ab11d8f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "print(f\"GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'None'}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9z_HR44SHpv",
        "outputId": "589a743d-5f28-493d-8785-88906e6f92e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA available: True\n",
            "GPU: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers datasets jsonlines scikit-learn\n",
        "!pip install pytorch-crf"
      ],
      "metadata": {
        "id": "Nsru_9u4Tygx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4e6adbe-1944-4041-89a0-08bddc92d2bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-crf\n",
            "  Downloading pytorch_crf-0.7.2-py3-none-any.whl.metadata (2.4 kB)\n",
            "Downloading pytorch_crf-0.7.2-py3-none-any.whl (9.5 kB)\n",
            "Installing collected packages: pytorch-crf\n",
            "Successfully installed pytorch-crf-0.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/asxd-10/cis5300_project.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkbTxmFBSVqT",
        "outputId": "46a1caf4-6ba6-40aa-ee1c-2b85b3d84b25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'cis5300_project'...\n",
            "remote: Enumerating objects: 186, done.\u001b[K\n",
            "remote: Counting objects: 100% (186/186), done.\u001b[K\n",
            "remote: Compressing objects: 100% (162/162), done.\u001b[K\n",
            "remote: Total 186 (delta 93), reused 71 (delta 17), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (186/186), 14.16 MiB | 6.07 MiB/s, done.\n",
            "Resolving deltas: 100% (93/93), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('cis5300_project')\n",
        "\n",
        "print('Contents of cis5300_project directory:')\n",
        "!ls -F cis5300_project/\n",
        "\n",
        "def load_pubmed_rct(path):\n",
        "    data = []\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if not line or line.startswith(\"###\"):\n",
        "                continue\n",
        "            label, sentence = line.split(\"\\t\", 1)\n",
        "            data.append((label, sentence))\n",
        "    return data\n",
        "\n",
        "def load_pubmed_rct_by_abstract(path):\n",
        "    \"\"\"\n",
        "    Returns a list of abstracts, each abstract is a tuple (labels, sentences)\n",
        "    \"\"\"\n",
        "    abstracts = []\n",
        "    current_labels = []\n",
        "    current_sents = []\n",
        "\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "            if line.startswith(\"###\"):\n",
        "                # Start of new abstract\n",
        "                if current_sents:  # save previous abstract\n",
        "                    abstracts.append((current_labels, current_sents))\n",
        "                    current_labels = []\n",
        "                    current_sents = []\n",
        "                continue\n",
        "            label, sentence = line.split(\"\\t\", 1)\n",
        "            current_labels.append(label)\n",
        "            current_sents.append(sentence)\n",
        "\n",
        "    # Add last abstract\n",
        "    if current_sents:\n",
        "        abstracts.append((current_labels, current_sents))\n",
        "\n",
        "    return abstracts\n",
        "\n",
        "print(\"Loading PubMed RCT data\")\n",
        "\n",
        "\n",
        "train_abstracts = load_pubmed_rct_by_abstract('cis5300_project/data/pubmed_rct/train.txt')\n",
        "dev_abstracts   = load_pubmed_rct_by_abstract('cis5300_project/data/pubmed_rct/dev.txt')\n",
        "test_abstracts  = load_pubmed_rct_by_abstract('cis5300_project/data/pubmed_rct/test.txt')\n",
        "\n",
        "print(f\"{len(train_abstracts)} training abstracts\")\n",
        "print(f\"{len(dev_abstracts)} dev abstracts\")\n",
        "print(f\"{len(test_abstracts)} test abstracts\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ll3JM97hSkWC",
        "outputId": "b30e3ba1-9e7a-4a3c-fa72-8076f05b9fca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contents of cis5300_project directory:\n",
            "data/\t\t     notebooks/  requirements.txt  src/\n",
            "download_scifact.sh  README.md\t setup.sh\n",
            "Loading PubMed RCT data\n",
            "15000 training abstracts\n",
            "2500 dev abstracts\n",
            "2500 test abstracts\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_abstracts[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oh5ybcSa_KmE",
        "outputId": "947be518-764f-4a46-e170-0e63d11c4c18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(['OBJECTIVE', 'METHODS', 'METHODS', 'METHODS', 'METHODS', 'METHODS', 'RESULTS', 'RESULTS', 'RESULTS', 'RESULTS', 'RESULTS', 'CONCLUSIONS'], ['To investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( OA ) .', 'A total of @ patients with primary knee OA were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .', 'Outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .', 'Pain was assessed using the visual analog pain scale ( @-@ mm ) .', 'Secondary outcome measures included the Western Ontario and McMaster Universities Osteoarthritis Index scores , patient global assessment ( PGA ) of the severity of knee OA , and @-min walk distance ( @MWD ) .', 'Serum levels of interleukin @ ( IL-@ ) , IL-@ , tumor necrosis factor ( TNF ) - , and high-sensitivity C-reactive protein ( hsCRP ) were measured .', 'There was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , PGA , and @MWD at @ weeks .', 'The mean difference between treatment arms ( @ % CI ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .', 'Further , there was a clinically relevant reduction in the serum levels of IL-@ , IL-@ , TNF - , and hsCRP at @ weeks in the intervention group when compared to the placebo group .', 'These differences remained significant at @ weeks .', 'The Outcome Measures in Rheumatology Clinical Trials-Osteoarthritis Research Society International responder rate was @ % in the intervention group and @ % in the placebo group ( p < @ ) .', 'Low-dose oral prednisolone had both a short-term and a longer sustained effect resulting in less knee pain , better physical function , and attenuation of systemic inflammation in older patients with knee OA ( ClinicalTrials.gov identifier NCT@ ) .'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocessing- only id mapping and lowercasing for simple baseline"
      ],
      "metadata": {
        "id": "omqI03KeTlK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label2id = {\n",
        "    \"BACKGROUND\": 0,\n",
        "    \"OBJECTIVE\": 1,\n",
        "    \"METHODS\": 2,\n",
        "    \"RESULTS\": 3,\n",
        "    \"CONCLUSIONS\": 4\n",
        "}\n",
        "id2label = {v: k for k, v in label2id.items()}"
      ],
      "metadata": {
        "id": "EdCdsy54V96j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict, Counter\n",
        "\n",
        "def preprocess(text):\n",
        "    \"\"\"\n",
        "    Clean and normalize text.\n",
        "    - Strip whitespace\n",
        "    - Lowercase\n",
        "    - Replace placeholders like '@' with <NUM>\n",
        "    \"\"\"\n",
        "    text = text.strip().lower()\n",
        "    text = text.replace(\"@\", \"<NUM>\")\n",
        "    return text\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "word_counter = Counter()\n",
        "for labels, sents in train_abstracts:\n",
        "    for sent in sents:\n",
        "        sent = preprocess(sent)\n",
        "        word_counter.update(sent.split())\n",
        "\n",
        "word2idx = {\"<PAD>\": 0, \"<UNK>\": 1}\n",
        "for i, word in enumerate(word_counter.keys(), start=2):\n",
        "    word2idx[word] = i\n",
        "\n",
        "idx2word = {idx: word for word, idx in word2idx.items()}\n",
        "\n",
        "VOCAB_SIZE = len(word2idx)\n",
        "print(\"Vocabulary size:\", VOCAB_SIZE)\n",
        "\n",
        "\n",
        "#Tokenization + Vocabulary\n",
        "\n",
        "def tokenize_sentence(sentence):\n",
        "    return sentence.split()\n",
        "\n",
        "def build_vocab(sentences):\n",
        "    \"\"\"\n",
        "    sentences: list of lists of sentences (abstracts)\n",
        "    \"\"\"\n",
        "    for abstract in sentences:\n",
        "        for sent in abstract:\n",
        "            for word in tokenize_sentence(sent):\n",
        "                _ = word2idx[word]\n",
        "\n",
        "# preprocessing to abstracts\n",
        "def encode_abstracts(abstracts):\n",
        "    \"\"\"\n",
        "    abstracts: list of tuples (labels, sentences)\n",
        "    Returns:\n",
        "        sentence_tokens: list of list of tokenized sentences\n",
        "        label_ids: list of list of label ids\n",
        "    \"\"\"\n",
        "    sentence_tokens = []\n",
        "    label_ids = []\n",
        "\n",
        "    for labels, sents in abstracts:\n",
        "        sent_list = [preprocess(s) for s in sents]\n",
        "        sentence_tokens.append(sent_list)\n",
        "        label_ids.append([label2id[l] for l in labels])\n",
        "\n",
        "    return sentence_tokens, label_ids"
      ],
      "metadata": {
        "id": "hgdCf2sfWEjA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3353fd8-39e2-4023-e74b-02d6aa0aa97b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 69734\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "def sentence_to_indices(sentence, word2idx, max_len=None):\n",
        "    indices = [word2idx.get(w, word2idx[\"<UNK>\"]) for w in sentence]\n",
        "    if max_len:\n",
        "        if len(indices) < max_len:\n",
        "            indices += [word2idx[\"<PAD>\"]] * (max_len - len(indices))\n",
        "        else:\n",
        "            indices = indices[:max_len]\n",
        "    return indices\n",
        "\n",
        "class PubMedSentenceDataset(Dataset):\n",
        "    def __init__(self, abstracts, label2id, word2idx, max_sent_len=100):\n",
        "        \"\"\"\n",
        "        abstracts: list of (labels, sentences)\n",
        "        Each sentence is tokenized and converted to word indices\n",
        "        \"\"\"\n",
        "        self.abstracts = abstracts\n",
        "        self.label2id = label2id\n",
        "        self.word2idx = word2idx\n",
        "        self.max_sent_len = max_sent_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.abstracts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        labels, sents = self.abstracts[idx]\n",
        "        sent_indices = []\n",
        "        for sent in sents:\n",
        "            tokens = preprocess(sent).split()\n",
        "            idxs = [self.word2idx.get(w, self.word2idx[\"<UNK>\"]) for w in tokens]\n",
        "            if len(idxs) < self.max_sent_len:\n",
        "                idxs += [self.word2idx[\"<PAD>\"]] * (self.max_sent_len - len(idxs))\n",
        "            else:\n",
        "                idxs = idxs[:self.max_sent_len]\n",
        "            sent_indices.append(torch.tensor(idxs, dtype=torch.long))\n",
        "\n",
        "        label_ids = torch.tensor([self.label2id[l] for l in labels], dtype=torch.long)\n",
        "        return sent_indices, label_ids\n",
        "\n",
        "\n",
        "# 3. Collate function for variable-length sequences\n",
        "# def collate_fn(batch):\n",
        "#     batch_x = [item[0] for item in batch]\n",
        "#     batch_y = [item[1] for item in batch]\n",
        "#     lengths = torch.tensor([len(x) for x in batch_x], dtype=torch.long)\n",
        "#     padded_x = torch.nn.utils.rnn.pad_sequence(batch_x, batch_first=True, padding_value=word2idx[\"<PAD>\"])\n",
        "#     batch_y = torch.stack(batch_y)\n",
        "#     mask = (padded_x != word2idx[\"<PAD>\"]).to(torch.uint8)\n",
        "#     return padded_x, batch_y, mask, lengths\n",
        "\n",
        "def collate_fn(batch):\n",
        "    \"\"\"\n",
        "    batch: list of (list of sentence tensors, label_ids)\n",
        "    Pads abstracts to same number of sentences\n",
        "    \"\"\"\n",
        "    max_sents = max(len(item[0]) for item in batch)\n",
        "\n",
        "    padded_sents = []\n",
        "    padded_labels = []\n",
        "    mask = []\n",
        "\n",
        "    for sents, labels in batch:\n",
        "        # Pad sentences\n",
        "        pad_count = max_sents - len(sents)\n",
        "        padded_sents.append(torch.stack(sents + [torch.zeros_like(sents[0])]*pad_count))\n",
        "        padded_labels.append(torch.cat([labels, torch.full((pad_count,), -1)]))  # -1 for padding labels\n",
        "        mask.append(torch.tensor([1]*len(sents) + [0]*pad_count, dtype=torch.bool))\n",
        "\n",
        "    padded_sents = torch.stack(padded_sents)  # (batch_size, seq_len, max_sent_len)\n",
        "    padded_labels = torch.stack(padded_labels)  # (batch_size, seq_len)\n",
        "    mask = torch.stack(mask)  # (batch_size, seq_len)\n",
        "\n",
        "    return padded_sents, padded_labels, mask\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Example usage:\n",
        "# train_dataset = PubMedDataset(train_sentences, train_labels, word2idx, max_len=100)\n",
        "# train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "# dev_dataset = PubMedDataset(dev_sentences, dev_labels, word2idx, max_len=100)\n",
        "# dev_loader = DataLoader(dev_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "print(\"Dataset and DataLoader ready.\")\n"
      ],
      "metadata": {
        "id": "7xiMZmSCAYsf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53b7cac0-2199-4718-dc75-2ccb9efb5620"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset and DataLoader ready.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchcrf import CRF\n",
        "\n",
        "class SentenceBiLSTM_CRF(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_labels, pad_idx):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=pad_idx)\n",
        "        self.lstm = nn.LSTM(embed_dim, hidden_dim//2, num_layers=1,\n",
        "                            batch_first=True, bidirectional=True)\n",
        "        self.hidden2tag = nn.Linear(hidden_dim, num_labels)\n",
        "        self.crf = CRF(num_labels, batch_first=True)\n",
        "\n",
        "    def forward(self, x, tags=None, mask=None):\n",
        "        \"\"\"\n",
        "        x: (batch_size, seq_len, max_sent_len)\n",
        "        tags: (batch_size, seq_len)\n",
        "        mask: (batch_size, seq_len)\n",
        "        \"\"\"\n",
        "        batch_size, seq_len, max_sent_len = x.shape\n",
        "        embeds = self.embedding(x)  # (B, S, L, E)\n",
        "        sent_embeds = embeds.mean(dim=2)  # average over tokens -> (B, S, E)\n",
        "\n",
        "        lstm_out, _ = self.lstm(sent_embeds)  # (B, S, H)\n",
        "        emissions = self.hidden2tag(lstm_out)  # (B, S, num_labels)\n",
        "\n",
        "        if tags is not None:\n",
        "            # Only compute loss on non-padded labels\n",
        "            loss = -self.crf(emissions, tags, mask=mask, reduction='mean')\n",
        "            return loss\n",
        "        else:\n",
        "            pred_tags = self.crf.decode(emissions, mask=mask)\n",
        "            return pred_tags\n",
        "\n",
        "\n",
        "# # Example usage\n",
        "# VOCAB_SIZE = len(word2idx)\n",
        "# EMBED_DIM = 100\n",
        "# HIDDEN_DIM = 256\n",
        "# NUM_LABELS = len(label2id)\n",
        "# PAD_IDX = word2idx[\"<PAD>\"]\n",
        "\n",
        "# model = BiLSTM_CRF(VOCAB_SIZE, EMBED_DIM, HIDDEN_DIM, NUM_LABELS, PAD_IDX)\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# model.to(device)\n",
        "\n",
        "# print(model)\n"
      ],
      "metadata": {
        "id": "-KoNLCo7Vp9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_sentences, train_labels = encode_abstracts(train_abstracts)\n",
        "# dev_sentences, dev_labels = encode_abstracts(dev_abstracts)\n",
        "# test_sentences, test_labels = encode_abstracts(test_abstracts)"
      ],
      "metadata": {
        "id": "_SmGdmHjWOLT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = PubMedSentenceDataset(train_abstracts, label2id, word2idx, max_sent_len=100)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "dev_dataset = PubMedSentenceDataset(dev_abstracts, label2id, word2idx, max_sent_len=100)\n",
        "dev_loader = DataLoader(dev_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)"
      ],
      "metadata": {
        "id": "bZc5utfuboq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SentenceBiLSTM_CRF(VOCAB_SIZE, EMBED_DIM, HIDDEN_DIM, NUM_LABELS, PAD_IDX)\n",
        "model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "LKC0URt4bqVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "\n",
        "def evaluate(loader):\n",
        "    model.eval()\n",
        "    all_preds, all_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch_x, batch_y, mask in loader:\n",
        "            batch_x, batch_y, mask = batch_x.to(device), batch_y.to(device), mask.to(device)\n",
        "            preds = model(batch_x, mask=mask)  # list of lists\n",
        "\n",
        "            for p, y, m in zip(preds, batch_y, mask):\n",
        "                valid_len = m.sum().item()\n",
        "                all_preds.extend(p[:valid_len])\n",
        "                all_labels.extend(y[:valid_len].tolist())\n",
        "\n",
        "    acc = accuracy_score(all_labels, all_preds)\n",
        "    macro_f1 = f1_score(all_labels, all_preds, average='macro')\n",
        "    return acc, macro_f1\n"
      ],
      "metadata": {
        "id": "rGw7xwhmcENl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 5\n",
        "best_f1 = 0.0  # keep track of best dev Macro-F1\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch_x, batch_y, mask in train_loader:\n",
        "        batch_x, batch_y, mask = batch_x.to(device), batch_y.to(device), mask.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        loss = model(batch_x, tags=batch_y, mask=mask)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "\n",
        "    # Evaluate on dev set\n",
        "    acc, macro_f1 = evaluate(dev_loader)\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS}, Loss: {avg_loss:.4f}\")\n",
        "    print(f\"Dev Accuracy: {acc:.4f}, Dev Macro-F1: {macro_f1:.4f}\")\n",
        "\n",
        "    if macro_f1 > best_f1:\n",
        "        best_f1 = macro_f1\n",
        "        torch.save(model.state_dict(), \"best_bilstm_crf_model.pt\")\n",
        "        print(f\"Model saved with Macro-F1: {best_f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tijYlbg2cOrl",
        "outputId": "63a705d6-1c45-4e9b-94cb-4e8b69d64d75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 6.8168\n",
            "Dev Accuracy: 0.8457, Dev Macro-F1: 0.7709\n",
            "Model saved with Macro-F1: 0.7709\n",
            "Epoch 2/5, Loss: 3.6906\n",
            "Dev Accuracy: 0.8707, Dev Macro-F1: 0.8075\n",
            "Model saved with Macro-F1: 0.8075\n",
            "Epoch 3/5, Loss: 2.9439\n",
            "Dev Accuracy: 0.8871, Dev Macro-F1: 0.8242\n",
            "Model saved with Macro-F1: 0.8242\n",
            "Epoch 4/5, Loss: 2.5479\n",
            "Dev Accuracy: 0.8920, Dev Macro-F1: 0.8344\n",
            "Model saved with Macro-F1: 0.8344\n",
            "Epoch 5/5, Loss: 2.2494\n",
            "Dev Accuracy: 0.8969, Dev Macro-F1: 0.8337\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load(\"best_bilstm_crf_model.pt\"))\n",
        "model.eval()\n",
        "\n",
        "test_dataset = PubMedSentenceDataset(test_abstracts, label2id, word2idx, max_sent_len=100)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "test_acc, test_macro_f1 = evaluate(test_loader)\n",
        "print(f\"Test Accuracy: {test_acc:.4f}, Test Macro-F1: {test_macro_f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dv_hquCicfrF",
        "outputId": "fd1f4c70-84e3-4c63-a3b5-1c0e34feceeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.8878, Test Macro-F1: 0.8335\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w8ElSzhOf89m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}