{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM1HdwCmFlOYv/rAE3qN5xG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asxd-10/cis5300_project/blob/main/notebooks/Final_Extension_BILSTM_section_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYnmLbEiOzvP",
        "outputId": "e8e6123d-6c2d-4079-c817-6443629925e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%env CUDA_LAUNCH_BLOCKING=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bD9Hw6xrBzHh",
        "outputId": "f573164f-9da7-4d35-b77a-4a9826a9cb8f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: CUDA_LAUNCH_BLOCKING=1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "print(f\"GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'None'}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9z_HR44SHpv",
        "outputId": "0dc7712e-98c3-44c5-9ea7-5e49972b2271"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA available: True\n",
            "GPU: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers datasets jsonlines scikit-learn\n",
        "!pip install pytorch-crf"
      ],
      "metadata": {
        "id": "Nsru_9u4Tygx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ef8640d-49a3-4f25-9650-a49bd9e9cdde"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytorch-crf in /usr/local/lib/python3.12/dist-packages (0.7.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/asxd-10/cis5300_project.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkbTxmFBSVqT",
        "outputId": "a7a3f9e5-771e-47b5-acff-eb8fb0da8164"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'cis5300_project' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('cis5300_project')\n",
        "\n",
        "print('Contents of cis5300_project directory:')\n",
        "!ls -F cis5300_project/\n",
        "\n",
        "def load_pubmed_rct(path):\n",
        "    data = []\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if not line or line.startswith(\"###\"):\n",
        "                continue\n",
        "            label, sentence = line.split(\"\\t\", 1)\n",
        "            data.append((label, sentence))\n",
        "    return data\n",
        "\n",
        "def load_pubmed_rct_by_abstract(path):\n",
        "    \"\"\"\n",
        "    Returns a list of abstracts, each abstract is a tuple (labels, sentences)\n",
        "    \"\"\"\n",
        "    abstracts = []\n",
        "    current_labels = []\n",
        "    current_sents = []\n",
        "\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "            if line.startswith(\"###\"):\n",
        "                if current_sents:  # save previous abstract\n",
        "                    abstracts.append((current_labels, current_sents))\n",
        "                    current_labels = []\n",
        "                    current_sents = []\n",
        "                continue\n",
        "            label, sentence = line.split(\"\\t\", 1)\n",
        "            current_labels.append(label)\n",
        "            current_sents.append(sentence)\n",
        "\n",
        "    if current_sents:\n",
        "        abstracts.append((current_labels, current_sents))\n",
        "\n",
        "    return abstracts\n",
        "\n",
        "print(\"Loading PubMed RCT data\")\n",
        "\n",
        "\n",
        "train_abstracts = load_pubmed_rct_by_abstract('cis5300_project/data/pubmed_rct/train.txt')\n",
        "dev_abstracts   = load_pubmed_rct_by_abstract('cis5300_project/data/pubmed_rct/dev.txt')\n",
        "test_abstracts  = load_pubmed_rct_by_abstract('cis5300_project/data/pubmed_rct/test.txt')\n",
        "\n",
        "print(f\"{len(train_abstracts)} training abstracts\")\n",
        "print(f\"{len(dev_abstracts)} dev abstracts\")\n",
        "print(f\"{len(test_abstracts)} test abstracts\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ll3JM97hSkWC",
        "outputId": "d7092d58-189b-4d9b-cd02-b555e74010e0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contents of cis5300_project directory:\n",
            "data/\t\t     notebooks/  requirements.txt  src/\n",
            "download_scifact.sh  README.md\t setup.sh\n",
            "Loading PubMed RCT data\n",
            "15000 training abstracts\n",
            "2500 dev abstracts\n",
            "2500 test abstracts\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_abstracts[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oh5ybcSa_KmE",
        "outputId": "cb6b2da0-1ed5-41b9-d405-7265efdf7551"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(['OBJECTIVE', 'METHODS', 'METHODS', 'METHODS', 'METHODS', 'METHODS', 'RESULTS', 'RESULTS', 'RESULTS', 'RESULTS', 'RESULTS', 'CONCLUSIONS'], ['To investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( OA ) .', 'A total of @ patients with primary knee OA were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .', 'Outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .', 'Pain was assessed using the visual analog pain scale ( @-@ mm ) .', 'Secondary outcome measures included the Western Ontario and McMaster Universities Osteoarthritis Index scores , patient global assessment ( PGA ) of the severity of knee OA , and @-min walk distance ( @MWD ) .', 'Serum levels of interleukin @ ( IL-@ ) , IL-@ , tumor necrosis factor ( TNF ) - , and high-sensitivity C-reactive protein ( hsCRP ) were measured .', 'There was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , PGA , and @MWD at @ weeks .', 'The mean difference between treatment arms ( @ % CI ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .', 'Further , there was a clinically relevant reduction in the serum levels of IL-@ , IL-@ , TNF - , and hsCRP at @ weeks in the intervention group when compared to the placebo group .', 'These differences remained significant at @ weeks .', 'The Outcome Measures in Rheumatology Clinical Trials-Osteoarthritis Research Society International responder rate was @ % in the intervention group and @ % in the placebo group ( p < @ ) .', 'Low-dose oral prednisolone had both a short-term and a longer sustained effect resulting in less knee pain , better physical function , and attenuation of systemic inflammation in older patients with knee OA ( ClinicalTrials.gov identifier NCT@ ) .'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocessing- only id mapping and lowercasing for simple baseline"
      ],
      "metadata": {
        "id": "omqI03KeTlK0"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label2id = {\n",
        "    \"BACKGROUND\": 0,\n",
        "    \"OBJECTIVE\": 1,\n",
        "    \"METHODS\": 2,\n",
        "    \"RESULTS\": 3,\n",
        "    \"CONCLUSIONS\": 4\n",
        "}\n",
        "id2label = {v: k for k, v in label2id.items()}"
      ],
      "metadata": {
        "id": "EdCdsy54V96j"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict, Counter\n",
        "\n",
        "def preprocess(text):\n",
        "    \"\"\"\n",
        "    Clean and normalize text.\n",
        "    - Strip whitespace\n",
        "    - Lowercase\n",
        "    - Replace placeholders like '@' with <NUM>\n",
        "    \"\"\"\n",
        "    text = text.strip().lower()\n",
        "    text = text.replace(\"@\", \"<NUM>\")\n",
        "    return text\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "word_counter = Counter()\n",
        "for labels, sents in train_abstracts:\n",
        "    for sent in sents:\n",
        "        sent = preprocess(sent)\n",
        "        word_counter.update(sent.split())\n",
        "\n",
        "word2idx = {\"<PAD>\": 0, \"<UNK>\": 1}\n",
        "for i, word in enumerate(word_counter.keys(), start=2):\n",
        "    word2idx[word] = i\n",
        "\n",
        "idx2word = {idx: word for word, idx in word2idx.items()}\n",
        "\n",
        "VOCAB_SIZE = len(word2idx)\n",
        "print(\"Vocabulary size:\", VOCAB_SIZE)\n",
        "\n",
        "\n",
        "#Tokenization + Vocabulary\n",
        "\n",
        "def tokenize_sentence(sentence):\n",
        "    return sentence.split()\n",
        "\n",
        "def build_vocab(sentences):\n",
        "    \"\"\"\n",
        "    sentences: list of lists of sentences (abstracts)\n",
        "    \"\"\"\n",
        "    for abstract in sentences:\n",
        "        for sent in abstract:\n",
        "            for word in tokenize_sentence(sent):\n",
        "                _ = word2idx[word]\n",
        "\n",
        "def encode_abstracts(abstracts):\n",
        "    \"\"\"\n",
        "    abstracts: list of tuples (labels, sentences)\n",
        "    Returns:\n",
        "        sentence_tokens: list of list of tokenized sentences\n",
        "        label_ids: list of list of label ids\n",
        "    \"\"\"\n",
        "    sentence_tokens = []\n",
        "    label_ids = []\n",
        "\n",
        "    for labels, sents in abstracts:\n",
        "        sent_list = [preprocess(s) for s in sents]\n",
        "        sentence_tokens.append(sent_list)\n",
        "        label_ids.append([label2id[l] for l in labels])\n",
        "\n",
        "    return sentence_tokens, label_ids"
      ],
      "metadata": {
        "id": "hgdCf2sfWEjA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d53f60f-6f5b-4267-fa9e-210bad93c62c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 69734\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "def sentence_to_indices(sentence, word2idx, max_len=None):\n",
        "    indices = [word2idx.get(w, word2idx[\"<UNK>\"]) for w in sentence]\n",
        "    if max_len:\n",
        "        if len(indices) < max_len:\n",
        "            indices += [word2idx[\"<PAD>\"]] * (max_len - len(indices))\n",
        "        else:\n",
        "            indices = indices[:max_len]\n",
        "    return indices\n",
        "\n",
        "class PubMedSentenceDataset(Dataset):\n",
        "    def __init__(self, abstracts, label2id, word2idx, max_sent_len=100):\n",
        "        \"\"\"\n",
        "        abstracts: list of (labels, sentences)\n",
        "        Each sentence is tokenized and converted to word indices\n",
        "        \"\"\"\n",
        "        self.abstracts = abstracts\n",
        "        self.label2id = label2id\n",
        "        self.word2idx = word2idx\n",
        "        self.max_sent_len = max_sent_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.abstracts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        labels, sents = self.abstracts[idx]\n",
        "        sent_indices = []\n",
        "        for sent in sents:\n",
        "            tokens = preprocess(sent).split()\n",
        "            idxs = [self.word2idx.get(w, self.word2idx[\"<UNK>\"]) for w in tokens]\n",
        "            if len(idxs) < self.max_sent_len:\n",
        "                idxs += [self.word2idx[\"<PAD>\"]] * (self.max_sent_len - len(idxs))\n",
        "            else:\n",
        "                idxs = idxs[:self.max_sent_len]\n",
        "            sent_indices.append(torch.tensor(idxs, dtype=torch.long))\n",
        "\n",
        "        label_ids = torch.tensor([self.label2id[l] for l in labels], dtype=torch.long)\n",
        "        return sent_indices, label_ids\n",
        "\n",
        "\n",
        "# 3. Collate function for variable-length sequences\n",
        "def collate_fn(batch):\n",
        "    \"\"\"\n",
        "    batch: list of (list of sentence tensors, label_ids)\n",
        "    Pads abstracts to same number of sentences\n",
        "    \"\"\"\n",
        "    max_sents = max(len(item[0]) for item in batch)\n",
        "\n",
        "    padded_sents = []\n",
        "    padded_labels = []\n",
        "    mask = []\n",
        "\n",
        "    for sents, labels in batch:\n",
        "        # Pad sentences\n",
        "        pad_count = max_sents - len(sents)\n",
        "        padded_sents.append(torch.stack(sents + [torch.zeros_like(sents[0])]*pad_count))\n",
        "        padded_labels.append(torch.cat([labels, torch.full((pad_count,), -1)]))  # -1 for padding labels\n",
        "        mask.append(torch.tensor([1]*len(sents) + [0]*pad_count, dtype=torch.bool))\n",
        "\n",
        "    padded_sents = torch.stack(padded_sents)  # (batch_size, seq_len, max_sent_len)\n",
        "    padded_labels = torch.stack(padded_labels)  # (batch_size, seq_len)\n",
        "    mask = torch.stack(mask)  # (batch_size, seq_len)\n",
        "\n",
        "    return padded_sents, padded_labels, mask\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "print(\"Dataset and DataLoader ready.\")\n"
      ],
      "metadata": {
        "id": "7xiMZmSCAYsf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cb6f6bc-e50a-4b3a-d1c5-0d41563996d6"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset and DataLoader ready.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchcrf import CRF\n",
        "\n",
        "class SentenceBiLSTM_CRF(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_labels, pad_idx, lstm_layers=2, dropout=0.3):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=pad_idx)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.lstm = nn.LSTM(\n",
        "            embed_dim,\n",
        "            hidden_dim // 2,\n",
        "            num_layers=lstm_layers,\n",
        "            batch_first=True,\n",
        "            bidirectional=True,\n",
        "            dropout=dropout\n",
        "        )\n",
        "\n",
        "        self.hidden2tag = nn.Linear(hidden_dim, num_labels)\n",
        "        self.crf = CRF(num_labels, batch_first=True)\n",
        "\n",
        "    def forward(self, x, tags=None, mask=None):\n",
        "        \"\"\"\n",
        "        x: (batch_size, seq_len, max_sent_len)\n",
        "        tags: (batch_size, seq_len)\n",
        "        mask: (batch_size, seq_len)\n",
        "        \"\"\"\n",
        "        batch_size, seq_len, max_sent_len = x.shape\n",
        "        embeds = self.embedding(x)           # (B, S, L, E)\n",
        "        sent_embeds = embeds.mean(dim=2)     # average over tokens -> (B, S, E)\n",
        "        sent_embeds = self.dropout(sent_embeds)\n",
        "\n",
        "        lstm_out, _ = self.lstm(sent_embeds) # (B, S, H)\n",
        "        lstm_out = self.dropout(lstm_out)\n",
        "\n",
        "        emissions = self.hidden2tag(lstm_out)  # (B, S, num_labels)\n",
        "\n",
        "        if tags is not None:\n",
        "            loss = -self.crf(emissions, tags, mask=mask, reduction='mean')\n",
        "            return loss\n",
        "        else:\n",
        "            pred_tags = self.crf.decode(emissions, mask=mask)\n",
        "            return pred_tags\n",
        "\n",
        "\n",
        "VOCAB_SIZE = len(word2idx)\n",
        "EMBED_DIM = 300\n",
        "HIDDEN_DIM = 256\n",
        "NUM_LABELS = len(label2id)\n",
        "PAD_IDX = word2idx[\"<PAD>\"]\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# model.to(device)\n",
        "\n",
        "# print(model)\n"
      ],
      "metadata": {
        "id": "-KoNLCo7Vp9k"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = PubMedSentenceDataset(train_abstracts, label2id, word2idx, max_sent_len=100)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "dev_dataset = PubMedSentenceDataset(dev_abstracts, label2id, word2idx, max_sent_len=100)\n",
        "dev_loader = DataLoader(dev_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)"
      ],
      "metadata": {
        "id": "bZc5utfuboq1"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SentenceBiLSTM_CRF(\n",
        "    VOCAB_SIZE, EMBED_DIM, HIDDEN_DIM, NUM_LABELS, PAD_IDX, lstm_layers=2, dropout=0.35\n",
        ")\n",
        "model.to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=1)\n",
        "\n",
        "print(model)"
      ],
      "metadata": {
        "id": "LKC0URt4bqVd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1472ada-53c7-4b7e-ab43-629152f4e312"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SentenceBiLSTM_CRF(\n",
            "  (embedding): Embedding(69734, 300, padding_idx=0)\n",
            "  (dropout): Dropout(p=0.35, inplace=False)\n",
            "  (lstm): LSTM(300, 128, num_layers=2, batch_first=True, dropout=0.35, bidirectional=True)\n",
            "  (hidden2tag): Linear(in_features=256, out_features=5, bias=True)\n",
            "  (crf): CRF(num_tags=5)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "\n",
        "def evaluate(loader):\n",
        "    model.eval()\n",
        "    all_preds, all_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch_x, batch_y, mask in loader:\n",
        "            batch_x, batch_y, mask = batch_x.to(device), batch_y.to(device), mask.to(device)\n",
        "            preds = model(batch_x, mask=mask)  # list of lists\n",
        "\n",
        "            for p, y, m in zip(preds, batch_y, mask):\n",
        "                valid_len = m.sum().item()\n",
        "                all_preds.extend(p[:valid_len])\n",
        "                all_labels.extend(y[:valid_len].tolist())\n",
        "\n",
        "    acc = accuracy_score(all_labels, all_preds)\n",
        "    macro_f1 = f1_score(all_labels, all_preds, average='macro')\n",
        "    return acc, macro_f1\n"
      ],
      "metadata": {
        "id": "rGw7xwhmcENl"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 15\n",
        "best_f1 = 0.0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch_x, batch_y, mask in train_loader:\n",
        "        batch_x, batch_y, mask = batch_x.to(device), batch_y.to(device), mask.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        loss = model(batch_x, tags=batch_y, mask=mask)\n",
        "        loss.backward()\n",
        "\n",
        "        # Gradient clipping\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n",
        "\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "\n",
        "    acc, macro_f1 = evaluate(dev_loader)\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS}, Loss: {avg_loss:.4f}\")\n",
        "    print(f\"Dev Accuracy: {acc:.4f}, Dev Macro-F1: {macro_f1:.4f}\")\n",
        "\n",
        "    scheduler.step(macro_f1)\n",
        "\n",
        "    if macro_f1 > best_f1:\n",
        "        best_f1 = macro_f1\n",
        "        torch.save(model.state_dict(), \"best_bilstm_crf_model.pt\")\n",
        "        print(f\"Model saved with Macro-F1: {best_f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tijYlbg2cOrl",
        "outputId": "79c6c656-338e-4c6b-8585-0a0bf9c6069e"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15, Loss: 5.9654\n",
            "Dev Accuracy: 0.8696, Dev Macro-F1: 0.8045\n",
            "Model saved with Macro-F1: 0.8045\n",
            "Epoch 2/15, Loss: 3.3389\n",
            "Dev Accuracy: 0.8879, Dev Macro-F1: 0.8232\n",
            "Model saved with Macro-F1: 0.8232\n",
            "Epoch 3/15, Loss: 2.7642\n",
            "Dev Accuracy: 0.8969, Dev Macro-F1: 0.8303\n",
            "Model saved with Macro-F1: 0.8303\n",
            "Epoch 4/15, Loss: 2.4162\n",
            "Dev Accuracy: 0.9015, Dev Macro-F1: 0.8383\n",
            "Model saved with Macro-F1: 0.8383\n",
            "Epoch 5/15, Loss: 2.1643\n",
            "Dev Accuracy: 0.9047, Dev Macro-F1: 0.8510\n",
            "Model saved with Macro-F1: 0.8510\n",
            "Epoch 6/15, Loss: 1.9559\n",
            "Dev Accuracy: 0.9090, Dev Macro-F1: 0.8537\n",
            "Model saved with Macro-F1: 0.8537\n",
            "Epoch 7/15, Loss: 1.7764\n",
            "Dev Accuracy: 0.9093, Dev Macro-F1: 0.8596\n",
            "Model saved with Macro-F1: 0.8596\n",
            "Epoch 8/15, Loss: 1.5974\n",
            "Dev Accuracy: 0.9142, Dev Macro-F1: 0.8611\n",
            "Model saved with Macro-F1: 0.8611\n",
            "Epoch 9/15, Loss: 1.4459\n",
            "Dev Accuracy: 0.9128, Dev Macro-F1: 0.8628\n",
            "Model saved with Macro-F1: 0.8628\n",
            "Epoch 10/15, Loss: 1.2978\n",
            "Dev Accuracy: 0.9139, Dev Macro-F1: 0.8669\n",
            "Model saved with Macro-F1: 0.8669\n",
            "Epoch 11/15, Loss: 1.1744\n",
            "Dev Accuracy: 0.9124, Dev Macro-F1: 0.8652\n",
            "Epoch 12/15, Loss: 1.0371\n",
            "Dev Accuracy: 0.9114, Dev Macro-F1: 0.8630\n",
            "Epoch 13/15, Loss: 0.8903\n",
            "Dev Accuracy: 0.9142, Dev Macro-F1: 0.8665\n",
            "Epoch 14/15, Loss: 0.8163\n",
            "Dev Accuracy: 0.9132, Dev Macro-F1: 0.8665\n",
            "Epoch 15/15, Loss: 0.7271\n",
            "Dev Accuracy: 0.9166, Dev Macro-F1: 0.8698\n",
            "Model saved with Macro-F1: 0.8698\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "FINE_TUNE_EPOCHS = 10         # max epochs for fine-tuning\n",
        "EARLY_STOP_PATIENCE = 3       # stop if no improvement for these many epochs\n",
        "FINE_LR = 0.0005              # smaller LR for fine-tuning\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=FINE_LR)\n",
        "\n",
        "best_f1 = 0.0\n",
        "patience_counter = 0\n",
        "\n",
        "for epoch in range(FINE_TUNE_EPOCHS):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch_x, batch_y, mask in train_loader:\n",
        "        batch_x, batch_y, mask = batch_x.to(device), batch_y.to(device), mask.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        loss = model(batch_x, tags=batch_y, mask=mask)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # gradient clipping\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "\n",
        "    acc, macro_f1 = evaluate(dev_loader)\n",
        "    print(f\"Epoch {epoch+1}/{FINE_TUNE_EPOCHS}, Loss: {avg_loss:.4f}\")\n",
        "    print(f\"Dev Accuracy: {acc:.4f}, Dev Macro-F1: {macro_f1:.4f}\")\n",
        "\n",
        "    if macro_f1 > best_f1:\n",
        "        best_f1 = macro_f1\n",
        "        torch.save(model.state_dict(), \"best_bilstm_crf_finetune.pt\")\n",
        "        print(f\"Model saved with Macro-F1: {best_f1:.4f}\")\n",
        "        patience_counter = 0\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        if patience_counter >= EARLY_STOP_PATIENCE:\n",
        "            print(f\"No improvement for {EARLY_STOP_PATIENCE} epochs. Early stopping...\")\n",
        "            break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEdBTHtPOh0w",
        "outputId": "ae6dc3b1-36cf-474a-f327-33b6e1be3d3f"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 0.7276\n",
            "Dev Accuracy: 0.9161, Dev Macro-F1: 0.8705\n",
            "Model saved with Macro-F1: 0.8705\n",
            "Epoch 2/10, Loss: 0.6797\n",
            "Dev Accuracy: 0.9147, Dev Macro-F1: 0.8668\n",
            "Epoch 3/10, Loss: 0.6420\n",
            "Dev Accuracy: 0.9169, Dev Macro-F1: 0.8704\n",
            "Epoch 4/10, Loss: 0.6066\n",
            "Dev Accuracy: 0.9155, Dev Macro-F1: 0.8691\n",
            "No improvement for 3 epochs. Early stopping...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.load_state_dict(torch.load(\"best_bilstm_crf_finetune.pt\"))\n",
        "model.eval()\n",
        "\n",
        "test_dataset = PubMedSentenceDataset(test_abstracts, label2id, word2idx, max_sent_len=100)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "test_acc, test_macro_f1 = evaluate(test_loader)\n",
        "print(f\"Test Accuracy: {test_acc:.4f}, Test Macro-F1: {test_macro_f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dv_hquCicfrF",
        "outputId": "877c3926-f5c2-4869-c9d3-4d0c06207aa5"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.9130, Test Macro-F1: 0.8667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def get_all_predictions(loader):\n",
        "    model.eval()\n",
        "    all_preds, all_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_x, batch_y, mask in loader:\n",
        "            batch_x, batch_y, mask = batch_x.to(device), batch_y.to(device), mask.to(device)\n",
        "            preds = model(batch_x, mask=mask)\n",
        "\n",
        "            for p, y, m in zip(preds, batch_y, mask):\n",
        "                valid_len = m.sum().item()\n",
        "                all_preds.extend(p[:valid_len])\n",
        "                all_labels.extend(y[:valid_len].tolist())\n",
        "\n",
        "    return all_labels, all_preds\n",
        "\n",
        "y_true, y_pred = get_all_predictions(test_loader)\n",
        "\n",
        "report = classification_report(\n",
        "    y_true,\n",
        "    y_pred,\n",
        "    target_names=[id2label[i] for i in range(NUM_LABELS)],\n",
        "    digits=4\n",
        ")\n",
        "\n",
        "print(\"\\n=== Detailed Classification Report for Test set===\\n\")\n",
        "print(report)\n"
      ],
      "metadata": {
        "id": "w8ElSzhOf89m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2c196f3-dc47-4739-cabf-430880d241c7"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Detailed Classification Report for Test set===\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  BACKGROUND     0.7811    0.8031    0.7919      3621\n",
            "   OBJECTIVE     0.7081    0.6622    0.6844      2333\n",
            "     METHODS     0.9433    0.9683    0.9556      9897\n",
            "     RESULTS     0.9554    0.9453    0.9503      9713\n",
            " CONCLUSIONS     0.9632    0.9398    0.9514      4571\n",
            "\n",
            "    accuracy                         0.9130     30135\n",
            "   macro avg     0.8702    0.8638    0.8667     30135\n",
            "weighted avg     0.9125    0.9130    0.9126     30135\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_true, y_pred = get_all_predictions(dev_loader)\n",
        "\n",
        "report = classification_report(\n",
        "    y_true,\n",
        "    y_pred,\n",
        "    target_names=[id2label[i] for i in range(NUM_LABELS)],\n",
        "    digits=4\n",
        ")\n",
        "\n",
        "print(\"\\n=== Detailed Classification Report for Dev Set===\\n\")\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3tqKCF9nO1T",
        "outputId": "25b8e7f4-9678-4f3f-b385-9149fa447dc1"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Detailed Classification Report for Dev Set===\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  BACKGROUND     0.7759    0.8049    0.7901      3449\n",
            "   OBJECTIVE     0.7272    0.6831    0.7044      2376\n",
            "     METHODS     0.9530    0.9667    0.9598      9964\n",
            "     RESULTS     0.9522    0.9525    0.9524      9841\n",
            " CONCLUSIONS     0.9600    0.9323    0.9460      4582\n",
            "\n",
            "    accuracy                         0.9161     30212\n",
            "   macro avg     0.8736    0.8679    0.8705     30212\n",
            "weighted avg     0.9158    0.9161    0.9158     30212\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LEpDDcClndyD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}